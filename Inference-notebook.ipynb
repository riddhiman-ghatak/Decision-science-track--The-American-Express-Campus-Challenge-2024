{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:33:13.868143Z","iopub.execute_input":"2024-06-18T06:33:13.868638Z","iopub.status.idle":"2024-06-18T06:33:15.022058Z","shell.execute_reply.started":"2024-06-18T06:33:13.868599Z","shell.execute_reply":"2024-06-18T06:33:15.020960Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/past-data-2/train_final_2.csv')\ntest = pd.read_csv('/kaggle/input/past-data-2/test_final_2.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:34:11.455651Z","iopub.execute_input":"2024-06-18T06:34:11.457252Z","iopub.status.idle":"2024-06-18T06:34:11.524600Z","shell.execute_reply.started":"2024-06-18T06:34:11.457203Z","shell.execute_reply":"2024-06-18T06:34:11.523503Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = train.drop(columns=['by_encoded'],axis=1)\ntest = test.drop(columns=['by_encoded'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:34:26.635942Z","iopub.execute_input":"2024-06-18T06:34:26.636330Z","iopub.status.idle":"2024-06-18T06:34:26.657233Z","shell.execute_reply.started":"2024-06-18T06:34:26.636300Z","shell.execute_reply":"2024-06-18T06:34:26.655782Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"X = train.drop(columns = ['winner_id','match id','team1_id','team2_id'])\ny = train['winner_id']","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:34:34.686478Z","iopub.execute_input":"2024-06-18T06:34:34.686932Z","iopub.status.idle":"2024-06-18T06:34:34.694503Z","shell.execute_reply.started":"2024-06-18T06:34:34.686901Z","shell.execute_reply":"2024-06-18T06:34:34.693053Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:34:45.882680Z","iopub.execute_input":"2024-06-18T06:34:45.883048Z","iopub.status.idle":"2024-06-18T06:34:48.347927Z","shell.execute_reply.started":"2024-06-18T06:34:45.883023Z","shell.execute_reply":"2024-06-18T06:34:48.346595Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score, KFold\ncat_model = CatBoostClassifier(verbose=0,iterations=500, depth=2, learning_rate=0.01, l2_leaf_reg=20,loss_function='Logloss', random_state=42)\n\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\ncross_val_scores = cross_val_score(cat_model, X_train, y_train, cv=kf, scoring='accuracy')\n\ncat_model.fit(X_train, y_train)\n\ny_pred = cat_model.predict(X_test)\ntrain_pred = cat_model.predict(X_train)\n\n# Evaluate the model\n\nprint(f'Cross-Validation Scores: {cross_val_scores}')\nprint(f'Mean Cross-Validation Accuracy: {np.mean(cross_val_scores)}')\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'test accuracy: {accuracy}')\n\naccuracy = accuracy_score(y_train, train_pred)\nprint(f'train accuracy: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:34:53.066926Z","iopub.execute_input":"2024-06-18T06:34:53.067462Z","iopub.status.idle":"2024-06-18T06:34:58.305372Z","shell.execute_reply.started":"2024-06-18T06:34:53.067431Z","shell.execute_reply":"2024-06-18T06:34:58.304121Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Cross-Validation Scores: [0.76315789 0.75       0.75       0.74834437 0.70860927]\nMean Cross-Validation Accuracy: 0.7440223074241896\ntest accuracy: 0.7736842105263158\ntrain accuracy: 0.7862796833773087\n","output_type":"stream"}]},{"cell_type":"code","source":"gbm_model = GradientBoostingClassifier(loss='log_loss', learning_rate=0.01, n_estimators=100,max_depth=2,verbose=0)\ngbm_model.fit(X_train, y_train)\n\ny_pred = gbm_model.predict(X_test)\ntrain_pred = gbm_model.predict(X_train)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'test accuracy: {accuracy}')\n\naccuracy = accuracy_score(y_train, train_pred)\nprint(f'train accuracy: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:35:08.428894Z","iopub.execute_input":"2024-06-18T06:35:08.429286Z","iopub.status.idle":"2024-06-18T06:35:09.413837Z","shell.execute_reply.started":"2024-06-18T06:35:08.429259Z","shell.execute_reply":"2024-06-18T06:35:09.412137Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"test accuracy: 0.7736842105263158\ntrain accuracy: 0.7823218997361477\n","output_type":"stream"}]},{"cell_type":"code","source":"import xgboost as xgb\nxgb_model = xgb.XGBClassifier(objective='binary:logistic',min_child_weight =6,gamma =9, eval_metric='logloss') \nxgb_model.fit(X_train, y_train)\n\ny_pred = xgb_model.predict(X_test)\ntrain_pred = xgb_model.predict(X_train)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'test accuracy: {accuracy}')\n\naccuracy = accuracy_score(y_train, train_pred)\nprint(f'train accuracy: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:35:14.983454Z","iopub.execute_input":"2024-06-18T06:35:14.984966Z","iopub.status.idle":"2024-06-18T06:35:15.185170Z","shell.execute_reply.started":"2024-06-18T06:35:14.984922Z","shell.execute_reply":"2024-06-18T06:35:15.184363Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"test accuracy: 0.7578947368421053\ntrain accuracy: 0.7902374670184696\n","output_type":"stream"}]},{"cell_type":"code","source":"import lightgbm as lgb\nlgb_model = lgb.LGBMClassifier(boosting_type='gbdt',metric = 'binary_logloss',learning_rate= 0.001, max_depth= -1, num_leaves= 5, feature_fraction= 0.7, bagging_fraction= 1, bagging_freq= 30, n_jobs=5, n_estimators=900, verbose= -1)\nlgb_model.fit(X_train, y_train)\n\ny_pred = lgb_model.predict(X_test)\ntrain_pred = lgb_model.predict(X_train)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'test accuracy: {accuracy}')\n\naccuracy = accuracy_score(y_train, train_pred)\nprint(f'train accuracy: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:35:22.238116Z","iopub.execute_input":"2024-06-18T06:35:22.238557Z","iopub.status.idle":"2024-06-18T06:35:24.408619Z","shell.execute_reply.started":"2024-06-18T06:35:22.238511Z","shell.execute_reply":"2024-06-18T06:35:24.407564Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"test accuracy: 0.7526315789473684\ntrain accuracy: 0.7849604221635884\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import VotingClassifier\nimport lightgbm as lgb\n\n\ncat_model = CatBoostClassifier(verbose=0,iterations=500, depth=2, learning_rate=0.01, l2_leaf_reg=20,loss_function='Logloss', random_state=42)\ngbm_model = GradientBoostingClassifier(loss='log_loss', learning_rate=0.01, n_estimators=200,max_depth=2,verbose=0)\nxgb_model = xgb.XGBClassifier(objective='binary:logistic',min_child_weight =6,gamma =9, eval_metric='logloss') \nlgb_model = lgb.LGBMClassifier(boosting_type='gbdt',metric = 'binary_logloss',learning_rate= 0.001, max_depth= -1, num_leaves= 5, feature_fraction= 0.7, bagging_fraction= 1, bagging_freq= 30, n_jobs=5, n_estimators=900, verbose= -1)\n\nensemble_model = VotingClassifier(estimators=[\n   ('gbm', gbm_model),\n    ('xgboost', xgb_model),\n    ('catboost', cat_model),\n    ('lgbm', lgb_model)\n], voting='soft') # 'soft' uses predicted probabilities; 'hard' uses predicted class labels\n\n# K-Fold Cross Validation\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\ncross_val_scores = cross_val_score(ensemble_model, X_train, y_train, cv=kf, scoring='accuracy')\n\n# Train ensemble model\nensemble_model.fit(X_train, y_train)\n\n# Predict on test set\ny_pred = ensemble_model.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Cross-Validation Scores: {cross_val_scores}')\nprint(f'Mean Cross-Validation Accuracy: {np.mean(cross_val_scores)}')\nprint(f'test accuracy: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:35:40.955180Z","iopub.execute_input":"2024-06-18T06:35:40.956386Z","iopub.status.idle":"2024-06-18T06:36:07.832678Z","shell.execute_reply.started":"2024-06-18T06:35:40.956341Z","shell.execute_reply":"2024-06-18T06:36:07.831616Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Cross-Validation Scores: [0.73026316 0.75       0.78289474 0.74834437 0.72847682]\nMean Cross-Validation Accuracy: 0.7479958173579645\ntest accuracy: 0.7736842105263158\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier\n\n\ncat_model = CatBoostClassifier(verbose=0,iterations=200, depth=2, learning_rate=0.01, l2_leaf_reg=20,loss_function='Logloss', random_state=42)\ngbm_model = GradientBoostingClassifier(loss='log_loss', learning_rate=0.01, n_estimators=800,max_depth=1,verbose=0)\nxgb_model = xgb.XGBClassifier(objective='binary:logistic',min_child_weight =6,gamma =9, eval_metric='logloss') \nlgb_model = lgb.LGBMClassifier(boosting_type='gbdt',metric = 'binary_logloss',learning_rate= 0.001, max_depth= -1, num_leaves= 5, feature_fraction= 0.7, bagging_fraction= 1, bagging_freq= 30, n_jobs=5, n_estimators=900, verbose= -1)\n\n# stacking_clf = StackingClassifier(\n#     estimators=[\n#         ('xgb', xgb_model),\n#         ('catboost', xgb_model),\n#         ('gbm', xgb_model),\n#         ('lgbm', xgb_model),\n#         ('xgb1',xgb_model),\n#         ('xgb2',xgb_model)\n#     ],\n#     final_estimator=xgb_model)\nstacking_clf = StackingClassifier(\n    estimators=[\n        ('xgb', cat_model),\n        ('catboost', cat_model),\n        ('gbm', cat_model),\n        ('lgbm', cat_model)\n    ],\n    final_estimator=cat_model)\n\n\n# stacking_clf = StackingClassifier(\n#     estimators=[\n#         ('gbm', gbm_model),\n#     ('xgboost', xgb_model),\n#     ('catboost', cat_model),\n#     ('lgbm', lgb_model)\n#     ],\n#     final_estimator=cat_model)\n# CatBoostClassifier(verbose=0,iterations=1000, depth=2, learning_rate=0.01, l2_leaf_reg=20,loss_function='Logloss', random_state=42 )\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\ncross_val_scores = cross_val_score(stacking_clf, X_train, y_train, cv=kf, scoring='accuracy')\n\n# Train ensemble model\nstacking_clf.fit(X_train, y_train)\n\n# Predict on test set\ny_pred = stacking_clf.predict(X_test)\ny_train_pred = stacking_clf.predict(X_train)\n\n# Evaluate the model\ntest_accuracy = accuracy_score(y_test, y_pred)\nprint(f'Cross-Validation Scores: {cross_val_scores}')\nprint(f'Mean Cross-Validation Accuracy: {np.mean(cross_val_scores)}')\nprint(f'test accuracy: {test_accuracy}')\n\ntrain_accuracy = accuracy_score(y_train, y_train_pred)\nprint(f'train accuracy: {train_accuracy}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Testing on actual test data**","metadata":{}},{"cell_type":"code","source":"X_test = test.drop(columns=['match id','team1_id','team2_id'],axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_model = CatBoostClassifier(verbose=0,iterations=500, depth=2, learning_rate=0.01, l2_leaf_reg=20,loss_function='Logloss', random_state=42)\ngbm_model = GradientBoostingClassifier(loss='log_loss', learning_rate=0.01, n_estimators=200,max_depth=2,verbose=0)\nxgb_model = xgb.XGBClassifier(objective='binary:logistic',min_child_weight =6,gamma =9, eval_metric='logloss') \nlgb_model = lgb.LGBMClassifier(boosting_type='gbdt',metric = 'binary_logloss',learning_rate= 0.001, max_depth= -1, num_leaves= 5, feature_fraction= 0.7, bagging_fraction= 1, bagging_freq= 30, n_jobs=5, n_estimators=900, verbose= -1)\n\nensemble_model = VotingClassifier(estimators=[\n    ('gbm', gbm_model),\n    ('xgboost', xgb_model),\n    ('catboost', cat_model),\n    ('lgbm', lgb_model)\n], voting='soft') # 'soft' uses predicted probabilities; 'hard' uses predicted class labels\n\n# stacking_clf = StackingClassifier(\n#     estimators=[\n#         ('xgb', cat_model),\n#         ('catboost', cat_model),\n#         ('gbm', cat_model),\n#         ('lgbm', cat_model)\n#     ],\n#     final_estimator=cat_model)\n# Train ensemble model\nensemble_model.fit(X, y)\n\ntest_cat_pred = ensemble_model.predict(X_test)\ntest_prob_scores = ensemble_model.predict_proba(X_test)\n\ntrain_cat_pred = ensemble_model.predict(X)\ntrain_prob_scores = ensemble_model.predict_proba(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_p_scores = np.amax(train_prob_scores,axis=1)\ntest_p_scores = np.amax(test_prob_scores,axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df = pd.read_csv('/kaggle/input/amex-bowl-hackathon/6645b7f8b0de7_sample_template/sample_template/submission_template_file1.csv')\nsample_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.DataFrame()\ndf_train['match id'] = train['match id']\ndf_train['dataset_type'] = 'train'\ndf_train['win_pred_team'] = train_cat_pred\ndf_train['win_pred_score'] = train_p_scores\ndf_train['train_algorithm'] = 'gbm;xgboost;catboost;lgbm'\ndf_train['is_ensemble'] = 'yes'\ndf_train['train_hps_trees'] = '200;100;500;900'\ndf_train['train_hps_depth'] = '2;3;2;-1'\ndf_train['train_hps_lr'] = '0.01;0.1;0.01;0.001'\ndf_train['team1'] = train['team1_id']\ndf_train['team2'] = train['team2_id']\n\ndf_test = pd.DataFrame()\ndf_test['match id'] = test['match id']\ndf_test['dataset_type'] = 'r1'\ndf_test['win_pred_team'] = test_cat_pred\ndf_test['win_pred_score'] = test_p_scores\ndf_test['train_algorithm'] = 'gbm;xgboost;catboost;lgbm'\ndf_test['is_ensemble'] = 'yes'\ndf_test['train_hps_trees'] = '200;100;500;900'\ndf_test['train_hps_depth'] = '2;3;2;-1'\ndf_test['train_hps_lr'] = '0.01;0.1;0.01;0.001'\ndf_test['team1'] = test['team1_id']\ndf_test['team2'] = test['team2_id']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train = pd.DataFrame()\n# df_train['match id'] = train['match id']\n# df_train['dataset_type'] = 'train'\n# df_train['win_pred_team'] = train_cat_pred\n# df_train['win_pred_score'] = train_p_scores\n# df_train['train_algorithm'] = 'catboost;catboost;catboost;catboost;catboost'\n# df_train['is_ensemble'] = 'yes'\n# df_train['train_hps_trees'] = '500;500;500;500;500'\n# df_train['train_hps_depth'] = '2;2;2;2;2'\n# df_train['train_hps_lr'] = '0.01;0.01;0.01;0.01;0.01'\n# df_train['team1'] = train['team1_id']\n# df_train['team2'] = train['team2_id']\n\n\n# df_test = pd.DataFrame()\n# df_test['match id'] = test['match id']\n# df_test['dataset_type'] = 'r1'\n# df_test['win_pred_team'] = test_cat_pred\n# df_test['win_pred_score'] = test_p_scores\n# df_test['train_algorithm'] ='catboost;catboost;catboost;catboost;catboost'\n# df_test['is_ensemble'] = 'yes'\n# df_test['train_hps_trees'] = '500;500;500;500;500'\n# df_test['train_hps_depth'] = '2;2;2;2;2'\n# df_test['train_hps_lr'] =  '0.01;0.01;0.01;0.01;0.01'\n# df_test['team1'] = test['team1_id']\n# df_test['team2'] = test['team2_id']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['win_pred_team_id'] = [df_test['team1'][i] if df_test['win_pred_team'][i] == 1 else df_test['team2'][i] for i in range(len(df_test))]\ndf_train['win_pred_team_id'] = [df_train['team1'][i] if df_train['win_pred_team'][i] == 1 else df_train['team2'][i] for i in range(len(df_train))]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.drop(columns = ['team1','team2','win_pred_team'],axis=1, inplace=True)\ndf_test.drop(columns = ['team1','team2','win_pred_team'],axis=1, inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = ['match id', 'dataset_type', 'win_pred_team_id', 'win_pred_score',\n       'train_algorithm', 'is_ensemble', 'train_hps_trees', 'train_hps_depth',\n       'train_hps_lr']\ndf_train = df_train[columns]\ndf_test = df_test[columns]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df_test, df_train], axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.set_index('match id', inplace=True)\nsample_df.set_index('match id', inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.reindex(sample_df.index)\ndf.reset_index(inplace=True)\nsample_df.reset_index(inplace=True)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Define columns\ncolumns = ['indep_feat_id1', 'indep_feat_id2', 'indep_feat_id3',\n           'indep_feat_id4', 'indep_feat_id5', 'indep_feat_id6',\n           'indep_feat_id7', 'indep_feat_id8', 'indep_feat_id9',\n           'indep_feat_id10']\n\n# Create DataFrame\nfeat_data = pd.DataFrame(columns=columns)\nfeat_data['match id'] = df['match id']\n\ni=1\nfor col in columns:\n    feat_data[col] = i\n    i+=1\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fil1_df = pd.concat([df, feat_data], axis=1)\nfil1_df.drop(columns=['match id'],axis=1,inplace=True)\nfil1_df['match id'] = df['match id']\nfil1_df = fil1_df[sample_df.columns]\nfil1_df['win_pred_team_id'] = fil1_df['win_pred_team_id'].astype('int64')\nfil1_df.to_csv('/kaggle/working/file1_new_imputation.csv',index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_model = CatBoostClassifier(verbose=0,iterations=500, depth=2, learning_rate=0.01, l2_leaf_reg=20,loss_function='Logloss', random_state=42)\ngbm_model = GradientBoostingClassifier(loss='log_loss', learning_rate=0.01, n_estimators=200,max_depth=2,verbose=0)\nxgb_model = xgb.XGBClassifier(objective='binary:logistic',min_child_weight =6,gamma =9, eval_metric='logloss') \nlgb_model = lgb.LGBMClassifier(boosting_type='gbdt',metric = 'binary_logloss',learning_rate= 0.001, max_depth= -1, num_leaves= 5, feature_fraction= 0.7, bagging_fraction= 1, bagging_freq= 30, n_jobs=5, n_estimators=900, verbose= -1)\n\nxgb_model.fit(X, y)\ngbm_model.fit(X, y)\nlgb_model.fit(X, y)\ncat_model.fit(X, y)\n\n# Extract Feature Importances\nxgb_importance = xgb_model.feature_importances_\ngbm_importance = gbm_model.feature_importances_\nlgbm_importance = lgb_model.feature_importances_\ncatboost_importance = cat_model.feature_importances_\ncatboost_importance = catboost_importance/100\nlgbm_importance = lgbm_importance/3600\n# Average Feature Importances\nfeature_importances = np.mean([xgb_importance, gbm_importance, lgbm_importance, catboost_importance], axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# feature_importance  = cat_model.feature_importances_\nfeature_importance_df = pd.DataFrame({'feature': X.columns, 'importance': feature_importances*100})\nfeature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\nsam = pd.read_csv('/kaggle/input/amex-bowl-hackathon/6645b7f8b0de7_sample_template/sample_template/submission_template_file2.csv')\nfeature_importance_df.reset_index(inplace=True)\nfeature_importance_df.drop(columns=['index'],axis=1,inplace=True)\nfeature_importance_df.rename(columns={'feature':'feat_name','importance':'model_feat_imp_train'},inplace=True)\n\nfeature_importance_df['feat_rank_train'] = feature_importance_df.index\nfeature_importance_df['feat_rank_train']= feature_importance_df['feat_rank_train']+1\n\nfeature_importance_df['feat_id'] = feature_importance_df['feat_rank_train']\nfeature_importance_df['feat_description'] = feature_importance_df['feat_name']\nfeature_importance_df = feature_importance_df[sam.columns]\n\nfeature_importance_df.to_csv('/kaggle/working/file2_new_imputation.csv',index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_importance_df","metadata":{},"execution_count":null,"outputs":[]}]}